// RUN: tf-mlir-translate -hlo-text-to-mlir-hlo -hlo-import-all-computations %s -o - | FileCheck %s
// RUN: tf-mlir-translate -hlo-text-to-mlir-hlo %s -o - | FileCheck %s -check-prefix=NO_DEAD_FUNCTION

// NO_DEAD_FUNCTION-NOT: @test

// CHECK: module @foobar
HloModule foobar

// Compiler-generated functions

// CHECK:  func private [[COPY_GENSYM:@.*copy.*]]([[INPUT:%.*]]: tensor<128x32xf32>) -> tensor<128x32xf32> attributes {execution_thread = "main"} {
  // CHECK-NEXT:  mhlo.copy [[INPUT]]

// CHECK: func private [[CP_GENSYM:@.*collective_permute_.*]]([[INPUT:%.*]]: tensor<128x32xf32>) -> tensor<128x32xf32> attributes {execution_thread = "main"} {
  // CHECK-NEXT:  "mhlo.collective_permute"([[INPUT]])
  // CHECK-SAME{LITERAL}:{source_target_pairs = dense<[[0, 1], [1, 2], [2, 3]]> : tensor<3x2xi64>} : (tensor<128x32xf32>) -> tensor<128x32xf32>

// CHECK:  func private [[AR_GENSYM:@.*all_reduce.*]]([[INPUT:%.*]]: tensor<128x32xf32>) -> tensor<128x32xf32> attributes {execution_thread = "main"} {
  // CHECK-NEXT:  "mhlo.all_reduce"([[INPUT]])
    // CHECK: [[BLOCK:^.*]]([[LHS:%.*]]: tensor<f32>, [[RHS:%.*]]: tensor<f32>):
    // CHECK: mhlo.add [[LHS]], [[RHS]]
  // CHECK: channel_handle = #mhlo.channel_handle<handle = 1, type = 0>
  // CHECK-SAME{LITERAL}: replica_groups = dense<[[0, 2, 4, 6], [1, 3, 5, 7]]> : tensor<2x4xi64>
  // CHECK: use_global_device_ids

// CHECK:  func private [[AG_GENSYM:@.*all_gather.*]]([[INPUT:%.*]]: tensor<128x32xf32>) -> tensor<128x128xf32> attributes {execution_thread = "main"} {
  // CHECK-NEXT:  "mhlo.all_gather"([[INPUT]])
  // CHECK-SAME: all_gather_dim = 1 : i64
  // CHECK-SAME: channel_handle = #mhlo.channel_handle<handle = 1, type = 0>
  // CHECK-SAME{LITERAL}: replica_groups = dense<[[0, 2, 4, 6], [1, 3, 5, 7]]> : tensor<2x4xi64>
  // CHECK: use_global_device_ids

// CHECK:  func @main(%arg0: tensor<f32>) -> tensor<f32> {
ENTRY %dummy_main (Arg_0.1: f32[]) -> f32[] {
  ROOT %Arg_0.1 = f32[] parameter(0)
}

// Tests

// CHECK:  func private @test_all_gather_start
// CHECK-SAME:  ([[INPUT:%.*]]: tensor<128x32xf32>)
%test_all_gather_start {
  input = f32[128,32] parameter(0)
  // CHECK-NEXT:  [[AG_START:%.*]] = "mhlo.async_start"([[INPUT]])
  // CHECK-SAME: called_computation = [[AG_GENSYM]], execution_thread = "main"
  ag-start = (f32[128,32], f32[128,128]) all-gather-start(input), channel_id=1, replica_groups={{0, 2, 4, 6}, {1, 3, 5, 7}}, dimensions={1}, use_global_device_ids=true
  // CHECK-NEXT:  "mhlo.async_done"([[AG_START]])
  // CHECK-SAME: called_computation = [[AG_GENSYM]], execution_thread = "main"
  ROOT ag-done = f32[128,128] all-gather-done(ag-start)
}

add {
  lhs = f32[] parameter(0)
  rhs = f32[] parameter(1)
  ROOT add = f32[] add(lhs, rhs)
}

// CHECK:  func private @test_all_reduce_start
// CHECK-SAME:  ([[INPUT:%.*]]: tensor<128x32xf32>)
%test_all_reduce_start {
  input = f32[128,32] parameter(0)
  // CHECK-NEXT:  [[AR_START:%.*]] = "mhlo.async_start"([[INPUT]])
  // CHECK-SAME: called_computation = [[AR_GENSYM]], execution_thread = "main"
  ar-start = (f32[128,32], f32[128,32]) all-reduce-start(input), channel_id=1, replica_groups={{0, 2, 4, 6}, {1, 3, 5, 7}}, to_apply=add, use_global_device_ids=true
  // CHECK-NEXT:  "mhlo.async_done"([[AR_START]])
  // CHECK-SAME: called_computation = [[AR_GENSYM]], execution_thread = "main"
  ROOT ar-done = f32[128,32] all-reduce-done(ar-start)
}

// CHECK:  func private @test_collective_permute
// CHECK-SAME:  ([[ARG:%.*]]: tensor<128x32xf32>) -> tensor<128x32xf32>
%test_collective_permute (input: f32[128,32]) -> f32[128,32] {
  %input = f32[128,32]{1,0} parameter(0)
  // CHECK-NEXT:  [[CP_START:%.*]] = "mhlo.async_start"([[ARG]])
  // CHECK-SAME: called_computation = [[CP_GENSYM]], execution_thread = "main"
  %cp-start = (f32[128,32]{1,0}, f32[128,32]) collective-permute-start(%input), source_target_pairs={{0,1},{1,2},{2,3}}
  // CHECK-NEXT:  "mhlo.async_done"([[CP_START]])
  // CHECK-SAME: called_computation = [[CP_GENSYM]], execution_thread = "main"
  ROOT %cp-done = f32[128,32]{1,0} collective-permute-done(%cp-start)
}

// CHECK:  func private @test_copy_start
// CHECK-SAME:  ([[INPUT:%.*]]: tensor<128x32xf32>)
%test_copy_start {
  input = f32[128,32] parameter(0)
  // CHECK-NEXT:  [[COPY_START:%.*]] = "mhlo.async_start"([[INPUT]])
  // CHECK-SAME: called_computation = [[COPY_GENSYM]], execution_thread = "main"
  copy-start = (f32[128,32], f32[128,32], u32[]) copy-start(input)
  // CHECK-NEXT: "mhlo.async_done"([[COPY_START]])
  // CHECK-SAME: called_computation = [[COPY_GENSYM]], execution_thread = "main"
  ROOT copy-done = f32[128,32] copy-done(copy-start)
}
